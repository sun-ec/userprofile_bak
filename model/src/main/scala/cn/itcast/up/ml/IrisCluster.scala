package cn.itcast.up.ml

import org.apache.spark.ml.clustering.{KMeans, KMeansModel}
import org.apache.spark.ml.feature.MinMaxScaler
import org.apache.spark.sql.{DataFrame, SparkSession}

/**
  * Author itcast
  * Date 2019/11/20 15:49
  * Desc 使用KMeans对鸢尾花数据集进行聚类
  * https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris
  * libsvm数据格式:<label> <index1>:<value1> <index2>:<value2> ...
  * 数据归一化
  * https://blog.csdn.net/m0_37870649/article/details/79535339
  * https://www.zhihu.com/question/28641663?sort=created
  */
object IrisCluster {
  def main(args: Array[String]): Unit = {
    //1.创建sparkSession
    val spark = SparkSession.builder()
      .appName("IrisDecisionTree")
      .master("local[*]")
      .getOrCreate()
    spark.sparkContext.setLogLevel("WARN")

    import spark.implicits._
    //2.加载数据
    val data: DataFrame = spark.read.format("libsvm").load("file:///D:\\data\\spark\\ml\\iris_kmeans.txt")
    //data.show(10,false)
    //data.printSchema()
    /*
 +-----+-------------------------------+
|label|features                       |
+-----+-------------------------------+
|1.0  |(4,[0,1,2,3],[5.1,3.5,1.4,0.2])|
|1.0  |(4,[0,1,2,3],[4.9,3.0,1.4,0.2])|
|1.0  |(4,[0,1,2,3],[4.7,3.2,1.3,0.2])|
|1.0  |(4,[0,1,2,3],[4.6,3.1,1.5,0.2])|
|1.0  |(4,[0,1,2,3],[5.0,3.6,1.4,0.2])|
|1.0  |(4,[0,1,2,3],[5.4,3.9,1.7,0.4])|
|1.0  |(4,[0,1,2,3],[4.6,3.4,1.4,0.3])|
|1.0  |(4,[0,1,2,3],[5.0,3.4,1.5,0.2])|
|1.0  |(4,[0,1,2,3],[4.4,2.9,1.4,0.2])|
|1.0  |(4,[0,1,2,3],[4.9,3.1,1.5,0.1])|
+-----+-------------------------------+
only showing top 10 rows

root
 |-- label: double (nullable = true)
 |-- features: vector (nullable = true)
     */

    //3.特征工程
    //注意:上面加载的libsvm数据集已经对数据的标签列进行了处理,对于特征列也进行了向量化
    //但是,为了提升模型收敛速度和模型精度,我们可以对特征数据进行归一化,将特征数据缩放到[0,1]之间
    val scalerData: DataFrame = new MinMaxScaler()
      .setInputCol("features")
      .setOutputCol("scalerFeatures")
      .fit(data)
      .transform(data)
    //scalerData.show(10,false)
    //scalerData.printSchema()
/*
+-----+-------------------------------+---------------------------------------------------------------------------------+
|label|features                       |scalerFeatures                                                                   |
+-----+-------------------------------+---------------------------------------------------------------------------------+
|1.0  |(4,[0,1,2,3],[5.1,3.5,1.4,0.2])|[0.22222222222222213,0.6249999999999999,0.06779661016949151,0.04166666666666667] |
|1.0  |(4,[0,1,2,3],[4.9,3.0,1.4,0.2])|[0.1666666666666668,0.41666666666666663,0.06779661016949151,0.04166666666666667] |
|1.0  |(4,[0,1,2,3],[4.7,3.2,1.3,0.2])|[0.11111111111111119,0.5,0.05084745762711865,0.04166666666666667]                |
|1.0  |(4,[0,1,2,3],[4.6,3.1,1.5,0.2])|[0.08333333333333327,0.4583333333333333,0.0847457627118644,0.04166666666666667]  |
|1.0  |(4,[0,1,2,3],[5.0,3.6,1.4,0.2])|[0.19444444444444448,0.6666666666666666,0.06779661016949151,0.04166666666666667] |
|1.0  |(4,[0,1,2,3],[5.4,3.9,1.7,0.4])|[0.30555555555555564,0.7916666666666665,0.11864406779661016,0.12500000000000003] |
|1.0  |(4,[0,1,2,3],[4.6,3.4,1.4,0.3])|[0.08333333333333327,0.5833333333333333,0.06779661016949151,0.08333333333333333] |
|1.0  |(4,[0,1,2,3],[5.0,3.4,1.5,0.2])|[0.19444444444444448,0.5833333333333333,0.0847457627118644,0.04166666666666667]  |
|1.0  |(4,[0,1,2,3],[4.4,2.9,1.4,0.2])|[0.027777777777777922,0.3749999999999999,0.06779661016949151,0.04166666666666667]|
|1.0  |(4,[0,1,2,3],[4.9,3.1,1.5,0.1])|[0.1666666666666668,0.4583333333333333,0.0847457627118644,0.0]                   |
+-----+-------------------------------+---------------------------------------------------------------------------------+
only showing top 10 rows

root
 |-- label: double (nullable = true)
 |-- features: vector (nullable = true)
 |-- scalerFeatures: vector (nullable = true)
 */

    //4.创建模型并训练
    val kmodel: KMeansModel = new KMeans()
      .setFeaturesCol("scalerFeatures")
      .setPredictionCol("predict")
      .setK(3) //聚类个数
      .setMaxIter(10) //最大迭代次数
      .setSeed(10) //设置随机种子,可以保证每次运行的结果一致
      .fit(scalerData)

    //5.预测/聚类
    val result: DataFrame = kmodel.transform(scalerData)

    //6.查看结果
    //result.show(10,false)
/*
+-----+-------------------------------+---------------------------------------------------------------------------------+-------+
|label|features                       |scalerFeatures                                                                   |predict|
+-----+-------------------------------+---------------------------------------------------------------------------------+-------+
|1.0  |(4,[0,1,2,3],[5.1,3.5,1.4,0.2])|[0.22222222222222213,0.6249999999999999,0.06779661016949151,0.04166666666666667] |0      |
|1.0  |(4,[0,1,2,3],[4.9,3.0,1.4,0.2])|[0.1666666666666668,0.41666666666666663,0.06779661016949151,0.04166666666666667] |0      |
|1.0  |(4,[0,1,2,3],[4.7,3.2,1.3,0.2])|[0.11111111111111119,0.5,0.05084745762711865,0.04166666666666667]                |0      |
|1.0  |(4,[0,1,2,3],[4.6,3.1,1.5,0.2])|[0.08333333333333327,0.4583333333333333,0.0847457627118644,0.04166666666666667]  |0      |
|1.0  |(4,[0,1,2,3],[5.0,3.6,1.4,0.2])|[0.19444444444444448,0.6666666666666666,0.06779661016949151,0.04166666666666667] |0      |
|1.0  |(4,[0,1,2,3],[5.4,3.9,1.7,0.4])|[0.30555555555555564,0.7916666666666665,0.11864406779661016,0.12500000000000003] |0      |
|1.0  |(4,[0,1,2,3],[4.6,3.4,1.4,0.3])|[0.08333333333333327,0.5833333333333333,0.06779661016949151,0.08333333333333333] |0      |
|1.0  |(4,[0,1,2,3],[5.0,3.4,1.5,0.2])|[0.19444444444444448,0.5833333333333333,0.0847457627118644,0.04166666666666667]  |0      |
|1.0  |(4,[0,1,2,3],[4.4,2.9,1.4,0.2])|[0.027777777777777922,0.3749999999999999,0.06779661016949151,0.04166666666666667]|0      |
|1.0  |(4,[0,1,2,3],[4.9,3.1,1.5,0.1])|[0.1666666666666668,0.4583333333333333,0.0847457627118644,0.0]                   |0      |
+-----+-------------------------------+---------------------------------------------------------------------------------+-------+
only showing top 10 rows
 */
    result.groupBy('label,'predict).count().show()
    /*
    +-----+-------+-----+
|label|predict|count|
+-----+-------+-----+
|  2.0|      1|   47|
|  1.0|      0|   50|
|  2.0|      2|    3|
|  3.0|      1|   14|
|  3.0|      2|   36|
+-----+-------+-----+
     */
  }
}
